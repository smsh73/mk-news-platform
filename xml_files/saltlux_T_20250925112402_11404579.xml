<?xml version="1.0" encoding="utf-8" ?>
<saltlux>
<article>
<action>T</action>
<wms_article>
<art_id>11404579</art_id>
<art_year>2025</art_year>
<art_no>613590</art_no>
<gubun>S</gubun>
<service_daytime>2025-08-27 21:51:20</service_daytime>
<title><![CDATA[챗GPT와 마지막 대화 나누고 떠난 16세...극단선택 방식 묻자 “나쁘지 않아”]]></title>
<sub_title><![CDATA[“챗GPT가 아들 죽음 도왔다”
美 부모, 올트먼·오픈AI에 소송
챗봇이 알려준대로 사망해 충격

청소년 과도한 AI 의존 부추겨
망상·현실 혼동 등 부작용 속출
美 정치권, 잇달아 규제 도입]]></sub_title>
<media_code>01</media_code>
<writers><![CDATA[원호섭 기자(wonc@mk.co.kr)]]></writers>
<free_type>F</free_type>
<pub_div>W</pub_div>
<pub_date></pub_date>
<pub_edition></pub_edition>
<pub_section></pub_section>
<pub_page></pub_page>
<reg_dt>2025-08-27 21:51:20</reg_dt>
<mod_dt></mod_dt>
<art_org_class>MK101507</art_org_class>
</wms_article>
<wms_article_body>
<body><![CDATA[<MKSUBTITLE><div style="display:box;border-left:solid 4px rgb(228, 228, 228);padding-left: 20px; padding-right: 20px;">“챗GPT가 아들 죽음 도왔다”<br>美 부모, 올트먼·오픈AI에 소송<br>챗봇이 알려준대로 사망해 충격<br><br>청소년 과도한 AI 의존 부추겨<br>망상·현실 혼동 등 부작용 속출<br>美 정치권, 잇달아 규제 도입</div></MKSUBTITLE>
<img src='https://wimg.mk.co.kr/news/cms/202508/27/news-p.v1.20250827.f2470e1f3a5a49f899ae115a021e129d_P2.png' alt=''>
지난 4월 미국 캘리포니아에서 16세 고등학생 애덤 레인이 스스로 목숨을 끊는 사건이 발생했다. 유서는 없었지만 가족은 그의 휴대전화에서 충격적인 기록을 찾았다. 챗GPT와 나눈 대화였다. 뉴욕타임스(NYT)에 따르면 레인이 챗GPT와 나눈 대화에는 극단적 선택과 관련된 구체적 방법이 포함돼 있었다. 올가미 사진을 본 챗GPT는 “꽤 괜찮다”는 답까지 했다. 레인의 부모는 이를 보고 “아들의 가장 친한 친구는 챗GPT였다”며 “챗GPT가 아들을 죽음으로 몰았다”고 말했다.
이들은 26일(현지시간) 샘 올트먼 오픈AI 최고경영자(CEO)와 오픈AI를 상대로 ‘업무상 과실에 따른 위법 사망’ 소송을 제기했다. 레인의 부모는 소장에서 “이번 비극은 단순한 오류가 아닌 의도적 설계의 결과물”이라며 “오픈AI는 시장 선점을 위해 안전 검토를 대폭 축소했다”고 지적했다.
최근 미국에서 인공지능(AI) 챗봇이 청소년과 대화하는 과정에서 잇따라 취약한 대응을 보인 사례가 보고되는 등 심각한 사회 문제로 번지고 있다. 기술적 한계가 사회적 위험으로 번지는 조짐에 정치권과 규제당국도 대응 수위를 높이고 있다.
최근 드러난 청소년과 챗봇 간 위험한 상호작용은 비단 레인 사건뿐만이 아니다. 이달 미국의 비영리단체 디지털혐오대응센터(CCDH)는 가짜 13세 계정으로 챗봇을 시험한 결과 술·마약 파티 계획이나 섭식장애 은폐 방법, 심지어 부모에게 남길 유서까지 제공받았다고 밝혔다. NYT에 따르면 보스턴의 정신과 의사 앤드루 클라크 역시 청소년으로 가장해 여러 챗봇과 대화한 결과 일부가 극단적 선택을 부추기거나 가족을 없애라는 조언을 내놓았다고 전했다.
<img src='https://wimg.mk.co.kr/news/cms/202508/27/news-p.v1.20250827.7622da4908434029aacab29ef80bbd76_P1.png' alt=''>
챗봇은 기본적으로 사용자의 발언에 공감하고 맞장구치도록 설계돼 있다. 이는 정서와 사고가 형성되는 청소년기에 과도한 의존을 부추기면서 오히려 비판적 사고 저하, 잘못된 정보의 사실화, 주체성 약화 등 여러 위험성을 일으킬 수 있다.
최근 공개된 메타의 내부 문건은 이러한 상황에 불을 지폈다. 로이터에 따르면 메타의 AI는 아동과 플러팅(연애 감정을 주고받는 행위)이나 관능적인 대화를 나누는 것이 허용돼 있었다. 메타는 취재가 시작되자 이러한 부분을 삭제했다.
최근 전 세계적으로 여러 사건이 보고되고 있는 ‘AI 정신병(AI Psychosis)’ 논란도 우려를 키우고 있다. AI 정신병은 공식 의학 용어는 아니지만 AI 챗봇과 장시간 상호작용한 이후 망상이나 현실 혼동, 조증 증세 등이 나타나는 현상을 지칭한다. 워싱턴포스트에 따르면 샌프란시스코의 한 정신과 의사는 올해에만 최소 12명의 환자가 챗봇 대화 이후 정신병 증세로 입원했다고 밝혔다.
이러한 상황이 계속되자 미 정치권과 정부가 나서고 있다. 조시 호울리 미 상원 의원은 메타에 자료 제출을 요구하며 조사를 촉구했고, 미국의 44개 주 법무장관은 지난 25일 “아동을 해치는 AI 제품에는 법적 책임을 묻겠다”는 내용이 담긴 공동 서한을 오픈AI, 메타, 앤스로픽, 구글과 같은 빅테크 기업에 전달했다.
뉴욕주와 유타주 등도 AI를 사람처럼 느끼고 대화하는 상황을 막기 위해 AI 챗봇과 대화 시 주기적으로 AI임을 고지하는 방안을 법제화했다. 유타주에서는 5월부터 시행됐으며 뉴욕주는 11월에 시작된다. 유타주는 의료 상담 업무 시 AI 단독 사용을 금지했고 뉴욕주는 모든 챗봇에 3시간마다 ‘AI임을 분명히 알리는 안내문’을 고지하도록 했다. 위반 시 하루 1만5000달러 이상의 벌금이 부과된다. 현재 캘리포니아 역시 이러한 제도 도입을 추진하고 있다. 일리노이주도 이달부터 AI 챗봇이 심리 치료를 하거나 대화 상담 시 주체가 되는 것을 금지했다.
<img src='https://wimg.mk.co.kr/news/cms/202508/27/news-p.v1.20250827.de124bdde2c24245b87b1d8e11479f52_P1.png' alt=' 연합뉴스'>
빅테크들도 대응책 마련에 고심하고 있다. 오픈AI는 26일 레인 부모의 소장을 받은 뒤 자살과 관련된 대화가 장시간 이어지면 자동으로 대화를 차단하는 장치, 부모가 자녀의 사용 내용을 관리할 수 있는 권한 확대 등의 대책을 발표했다. 또 AI 정신병을 막기 위해 오픈AI는 장시간 대화 시 휴식을 권유하는 알람을 보내고 메타는 해로운 대화가 이어지면 자동으로 차단하는 기능을 강화하고 있다고 밝혔다.
미국 정책 분석 사이트인 글로벌 폴리시 워치에 따르면 올해 들어 60개 이상의 규제가 제정됐거나 시행됐다.
이번 논란은 10여 년 전부터 불거진 소셜미디어 규제 논의를 떠올리게 한다. 당시 페이스북(메타), 인스타그램, 틱톡 등과 같은 소셜미디어 플랫폼이 청소년의 우울증, 불안, 자해 충동을 심화시킨다는 연구 결과가 잇따라 발표되면서 사회적 파장이 컸다. 정치권은 나이 확인, 부모 통제, 추천 알고리즘 제한 등 다양한 대책을 추진했으며 이와 관련해 여러 소송이 이어졌다. 이 과정에서 빅테크 기업들은 계정 생성 시 나이 확인 절차 의무화, 부모 동의 없이 미성년자 가입 불가와 같은 규제를 받아들였다.
AI 챗봇을 둘러싼 현재의 논란도 이와 유사하다. 하지만 챗봇은 단순한 대화 상대를 넘어 청소년의 정서와 사고에 직접 개입할 수 있는 만큼 파급력은 소셜미디어보다 클 수 있다는 우려가 나온다.
]]></body>
</wms_article_body>
<wms_article_summary>
<summary><![CDATA[“챗GPT가 아들 죽음 도왔다” 美 부모, 올트먼·오픈AI에 소송 챗봇이 알려준대로 사망해 충격  청소년 과도한 AI 의존 부추겨 망상·현실 혼동 등 부작용 속출 美 정치권, 잇달아 규제 도입지난 4월 미국 캘리포니아에서 16세 고등학생 애덤 레인이 스스로 목숨을 끊는 사건이 발생했다. 유서는 없었지만 가족은 그의 휴대전화에서 충격적인 기록을 찾았다. 챗G]]></summary>
</wms_article_summary>
<stock_codes>
</stock_codes>
<wms_article_keywords>
</wms_article_keywords>
<wms_code_classes>
<wms_code_class>
<code_id>MK101507</code_id>
<code_nm><![CDATA[인공지능]]></code_nm>
<large_code_id>0</large_code_id>
<large_code_nm><![CDATA[뉴스]]></large_code_nm>
<middle_code_id>00559</middle_code_id>
<middle_code_nm><![CDATA[IT·과학]]></middle_code_nm>
<small_code_id>MK101507</small_code_id>
<small_code_nm><![CDATA[인공지능]]></small_code_nm>
</wms_code_class>
<wms_code_class>
<code_id>MK101505</code_id>
<code_nm><![CDATA[보안/해킹]]></code_nm>
<large_code_id>0</large_code_id>
<large_code_nm><![CDATA[뉴스]]></large_code_nm>
<middle_code_id>00559</middle_code_id>
<middle_code_nm><![CDATA[IT·과학]]></middle_code_nm>
<small_code_id>MK101505</small_code_id>
<small_code_nm><![CDATA[보안/해킹]]></small_code_nm>
</wms_code_class>
<wms_code_class>
<code_id>MK101508</code_id>
<code_nm><![CDATA[빅데이터]]></code_nm>
<large_code_id>0</large_code_id>
<large_code_nm><![CDATA[뉴스]]></large_code_nm>
<middle_code_id>00559</middle_code_id>
<middle_code_nm><![CDATA[IT·과학]]></middle_code_nm>
<small_code_id>MK101508</small_code_id>
<small_code_nm><![CDATA[빅데이터]]></small_code_nm>
</wms_code_class>
</wms_code_classes>
<wms_article_images>
<wms_article_image>
<image_url><![CDATA[https://wimg.mk.co.kr/news/cms/202508/27/news-p.v1.20250827.f2470e1f3a5a49f899ae115a021e129d_P2.png]]></image_url>
<image_caption><![CDATA[]]></image_caption>
</wms_article_image>
<wms_article_image>
<image_url><![CDATA[https://wimg.mk.co.kr/news/cms/202508/27/news-p.v1.20250827.7622da4908434029aacab29ef80bbd76_P1.png]]></image_url>
<image_caption><![CDATA[]]></image_caption>
</wms_article_image>
<wms_article_image>
<image_url><![CDATA[https://wimg.mk.co.kr/news/cms/202508/27/news-p.v1.20250827.de124bdde2c24245b87b1d8e11479f52_P1.png]]></image_url>
<image_caption><![CDATA[ 연합뉴스]]></image_caption>
</wms_article_image>
</wms_article_images>
<article_url><![CDATA[https://www.mk.co.kr/article/11404579]]></article_url>
</article>
</saltlux>
