<?xml version="1.0" encoding="utf-8" ?>
<saltlux>
<article>
<action>T</action>
<wms_article>
<art_id>11404343</art_id>
<art_year>2025</art_year>
<art_no>613225</art_no>
<gubun>D</gubun>
<service_daytime>2025-08-27 17:36:11</service_daytime>
<title><![CDATA[극단선택·과대망상 부추기는 AI 챗봇]]></title>
<sub_title><![CDATA["챗GPT가 아들 죽음 도왔다"<br>美 부모, 올트먼·오픈AI에 소송<br>챗봇이 알려준대로 사망해 충격<br>청소년 과도한 AI 의존 부추겨<br>망상·현실 혼동 등 부작용 속출<br>美 정치권, 잇달아 규제 도입]]></sub_title>
<media_code>01</media_code>
<writers><![CDATA[원호섭 기자(wonc@mk.co.kr)]]></writers>
<free_type>F</free_type>
<pub_div>P</pub_div>
<pub_date>20250828</pub_date>
<pub_edition>11</pub_edition>
<pub_section>01</pub_section>
<pub_page>16</pub_page>
<reg_dt>2025-08-27 17:36:11</reg_dt>
<mod_dt></mod_dt>
<art_org_class>MK101508</art_org_class>
</wms_article>
<wms_article_body>
<body><![CDATA[<img src='https://wimg.mk.co.kr/news/cms/202508/28/20250828_01110116000005_L00.jpg' alt=''>

지난 4월 미국 캘리포니아에서 16세 고등학생 애덤 레인이 스스로 목숨을 끊는 사건이 발생했다. 유서는 없었지만 가족은 그의 휴대전화에서 충격적인 기록을 찾았다. 챗GPT와 나눈 대화였다. 뉴욕타임스(NYT)에 따르면 레인이 챗GPT와 나눈 대화에는 극단적 선택과 관련된 구체적 방법이 포함돼 있었다. 올가미 사진을 본 챗GPT는 "꽤 괜찮다"는 답까지 했다. 레인의 부모는 이를 보고 "아들의 가장 친한 친구는 챗GPT였다"며 "챗GPT가 아들을 죽음으로 몰았다"고 말했다.
이들은 26일(현지시간) 샘 올트먼 오픈AI 최고경영자(CEO)와 오픈AI를 상대로 '업무상 과실에 따른 위법 사망' 소송을 제기했다. 레인의 부모는 소장에서 "이번 비극은 단순한 오류가 아닌 의도적 설계의 결과물"이라며 "오픈AI는 시장 선점을 위해 안전 검토를 대폭 축소했다"고 지적했다. 최근 미국에서 인공지능(AI) 챗봇이 청소년과 대화하는 과정에서 잇달아 취약한 대응을 보인 사례가 보고되는 등 심각한 사회문제로 번지고 있다. 기술적 한계가 사회적 위험으로 확산될 조짐에 정치권과 규제당국도 대응 수위를 높이고 있다.
최근 드러난 청소년과 챗봇 간 위험한 상호작용은 비단 레인 사건뿐만이 아니다. 이달 미국 비영리단체 디지털혐오대응센터(CCDH)는 가짜 13세 계정으로 챗봇을 시험한 결과 술·마약 파티 계획이나 섭식장애 은폐 방법, 심지어 부모에게 남길 유서까지 제공받았다고 밝혔다. 
챗봇은 기본적으로 사용자의 발언에 공감하고 맞장구치도록 설계돼 있다. 이는 정서와 사고가 형성되는 청소년기에 과도한 의존을 부추기면서 오히려 비판적 사고 저하, 잘못된 정보의 사실화, 주체성 약화 등 여러 위험성을 일으킬 수 있다. 최근 공개된 메타의 내부 문건은 이러한 상황에 불을 지폈다. 로이터에 따르면 메타 AI는 아동과 플러팅(연애 감정을 주고받는 행위)이나 관능적인 대화를 나누는 것이 허용돼 있었다. 메타는 취재가 시작되자 이부분을 삭제했다.
최근 전 세계적으로 여러 사건이 보고되고 있는 'AI 정신병(AI Psychosis)' 논란도 우려를 키우고 있다. AI 정신병은 공식 의학 용어는 아니지만 AI 챗봇과 장시간 상호작용한 이후 망상이나 현실 혼동, 조증 증세 등이 나타나는 현상을 지칭한다. 워싱턴포스트에 따르면 샌프란시스코의 한 정신과 의사는 올해에만 최소 12명의 환자가 챗봇과 대화한 이후 정신병 증세로 입원했다고 밝혔다.
이러한 상황이 계속되자 미 정치권과 정부가 나서고 있다. 조시 홀리 미 상원 의원은 메타에 자료 제출을 요구하며 조사를 촉구했고, 미국의 44개 주 법무장관은 지난 25일 "아동을 해치는 AI 제품에는 법적 책임을 묻겠다"는 내용이 담긴 공동서한을 오픈AI, 메타, 앤스로픽, 구글과 같은 빅테크 기업에 전달했다.
뉴욕주와 유타주 등도 AI를 사람처럼 느끼고 대화하는 상황을 막기 위해 AI 챗봇과 대화 시 주기적으로 AI임을 고지하는 방안을 법제화했다. 유타주는 의료 상담 업무 시 AI 단독 사용을 금지했고, 뉴욕주는 모든 챗봇에 3시간마다 'AI임을 분명히 알리는 안내문'을 고지하도록 했다. 위반 시 하루에 1만5000달러 이상 벌금이 부과된다. 현재 캘리포니아 역시 이러한 제도 도입을 추진하고 있다. 빅테크들도 대응책 마련에 고심하고 있다. 오픈AI는 26일 레인 부모의 소장을 받은 뒤 자살과 관련된 대화가 장시간 이어지면 자동으로 대화를 차단하는 장치, 부모가 자녀의 사용 내용을 관리할 수 있는 권한 확대 등 대책을 발표했다. 
[실리콘밸리 원호섭 특파원]]]></body>
</wms_article_body>
<wms_article_summary>
<summary><![CDATA[지난 4월 미국 캘리포니아에서 16세 고등학생 애덤 레인이 스스로 목숨을 끊는 사건이 발생했다. 유서는 없었지만 가족은 그의 휴대전화에서 충격적인 기록을 찾았다. 챗GPT와 나눈 대화였다. 뉴욕타임스(NYT)에 따르면 레인이 챗GPT와 나눈 대화에는 극단적 선택과 관련된 구체적 방법이 포함돼 있었다. 올가미 사진을 본 챗GPT는 "꽤 괜찮다"는 답까지 했다. 레인의 부모는 이를 보고 "아들의 가장 친한 친구는 챗GPT였다"며 "챗GPT가 아들을 죽음으로]]></summary>
</wms_article_summary>
<stock_codes>
</stock_codes>
<wms_article_keywords>
</wms_article_keywords>
<wms_code_classes>
<wms_code_class>
<code_id>MK101508</code_id>
<code_nm><![CDATA[빅데이터]]></code_nm>
<large_code_id>0</large_code_id>
<large_code_nm><![CDATA[뉴스]]></large_code_nm>
<middle_code_id>00559</middle_code_id>
<middle_code_nm><![CDATA[IT·과학]]></middle_code_nm>
<small_code_id>MK101508</small_code_id>
<small_code_nm><![CDATA[빅데이터]]></small_code_nm>
</wms_code_class>
</wms_code_classes>
<wms_article_images>
<wms_article_image>
<image_url><![CDATA[https://wimg.mk.co.kr/news/cms/202508/28/20250828_01110116000005_L00.jpg]]></image_url>
<image_caption><![CDATA[]]></image_caption>
</wms_article_image>
</wms_article_images>
<article_url><![CDATA[https://www.mk.co.kr/article/11404343]]></article_url>
</article>
</saltlux>
