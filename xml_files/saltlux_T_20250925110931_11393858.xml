<?xml version="1.0" encoding="utf-8" ?>
<saltlux>
<article>
<action>T</action>
<wms_article>
<art_id>11393858</art_id>
<art_year>2025</art_year>
<art_no>581851</art_no>
<gubun>S</gubun>
<service_daytime>2025-08-14 15:04:48</service_daytime>
<title><![CDATA[네이버 AI, 글로벌 개발자들 ‘즐겨찾기’에 찍혔다…오픈소스 다운로드도 150만 돌파]]></title>
<sub_title><![CDATA[4월 개방한 ‘하이퍼클로바 X 시드 3B’
국내 멀티모달 모델 중 최초로
깃허브 ‘vLLM 프로젝트’ 공식 지원 등재
글로벌 개발자 플랫폼에서 기술력 입증]]></sub_title>
<media_code>01</media_code>
<writers><![CDATA[안선제 기자(ahn.sunje@mk.co.kr)]]></writers>
<free_type>F</free_type>
<pub_div>W</pub_div>
<pub_date></pub_date>
<pub_edition></pub_edition>
<pub_section></pub_section>
<pub_page></pub_page>
<reg_dt>2025-08-14 15:04:48</reg_dt>
<mod_dt></mod_dt>
<art_org_class>MK101507</art_org_class>
</wms_article>
<wms_article_body>
<body><![CDATA[<MKSUBTITLE><div style="display:box;border-left:solid 4px rgb(228, 228, 228);padding-left: 20px; padding-right: 20px;">4월 개방한 ‘하이퍼클로바 X 시드 3B’<br>국내 멀티모달 모델 중 최초로<br>깃허브 ‘vLLM 프로젝트’ 공식 지원 등재<br>글로벌 개발자 플랫폼에서 기술력 입증</div></MKSUBTITLE>
<img src='https://wimg.mk.co.kr/news/cms/202508/14/news-p.v1.20250808.b5418fd784c9474c8626463e534f6c7d_P1.jpeg' alt=' [사진 = 네이버]'>
네이버가 지난 4월 오픈소스로 공개한 경량 멀티모달 인공지능(AI) 모델 ‘하이퍼클로바 X 시드 3B’가 글로벌 무대에서 존재감을 각인시키고 있다. 최근에는 전 세계 개발자들의 ‘즐겨찾기’로 통하는 깃허브 오픈소스 AI 서빙 시스템에 공식 지원 모델로 이름을 올리며 멀티모달 기술력과 대중성을 동시에 인정받았다.
14일 정보기술(IT) 업계에 따르면 30억개의 파라미터로 구성된 네이버의 ‘하이퍼클로바 X 시드 3B’ 모델은 지난달 25일 글로벌 AI 플랫폼 ‘깃허브’에서 운용되는 오픈소스 AI 서빙 시스템인 ‘vLLM(버추얼 LLM) 프로젝트’에서 공식 지원 목록에 등재됐다. 국내 멀티모달 모델이 이 명단에 포함된 건 이번이 처음이다.
오픈소스 모델을 실제 서비스에 적용하려면 AI 모델을 운영하고 실행하는 ‘서빙’이라는 작업이 필요한데, vLLM 프로젝트는 전 세계 개발자들이 가장 많이 쓰는 서빙 엔진이자 사실상 업계 ‘표준’으로 통한다.
vLLM 프로젝트는 전 세계에서 발표되는 수많은 오픈소스 거대언어모델(LLM) 가운데 주요 모델에 한해 서빙 시스템을 공식 제공해 개발자들이 보다 쉽게 활용할 수 있도록 지원하는데, 이 목록에 네이버 모델이 포함된 것이다. 즉 글로벌 개발자들의 ‘즐겨찾기’에 이름을 올린 셈이다.
목록에는 메타의 ‘라마’, 구글의 ‘젬마’, 마이크로소프트의 ‘파이’, 알리바바의 ‘큐원’ 등 글로벌 주요 AI 모델이 등재되어 있다.
업계 관계자는 “vLLM 공식 지원 목록에 올라가려면 vLLM 개발팀 및 커뮤니티의 리뷰와 테스트를 거쳐야 한다”며 “특히 하이퍼클로바X 오픈소스 모델의 경우 허깅페이스에서의 높은 다운로드 수 등 vLLM에 등록해달라는 개발자 커뮤니티의 니즈도 있었던 것으로 파악된다”고 설명했다.
<img src='https://wimg.mk.co.kr/news/cms/202508/14/news-p.v1.20250808.defaf1ce428c40a4b992f734ddb40de8_P1.png' alt=' 깃허브 vLLM 공식 지원 공지 [사진 = 네이버]'>
실제 하이퍼클로바 X 시드 3B 모델은 또다른 주요 글로벌 AI 오픈소스 플랫폼인 ‘허깅페이스’에서 인기있는 AI 모델로 주목받고 있다.
최근에는 공개 약 3개월 만에 150만 다운로드를 돌파했다. 불과 지난달에 시드 3종 모델을 합쳐 100만 회를 넘겼다는 소식이 전해졌던 것을 감안하면 단기간에 이뤄낸 가파른 성장이다.
최근 한달 기준으로만 해도 약 60만 다운로드 기록을 보여주고 있다. 같은 시기에 공개된 시드 1.5B(15억개 파라미터), 0.5B(5억 파라미터) 모델이 1만회 수준에 그친 것과 비교하면 격차가 크다. 지난달 공개한 추론 모델(싱크)도 보름 간 3만 다운로드 정도다.
업계에서는 이번 vLLM 공식 지원으로 접근성이 높아진 만큼 하이퍼클로바X 오픈소스 생태계는 더욱 빠르게 확장될 것이라는 전망이 나온다.
이에 대해 네이버 관계자는 “실제 서비스와 산업 현장에서 가치를 만들어내는 AI 모델 구축을 위해 텍스트뿐만 아니라 이미지, 오디오, 비디오까지 처리할 수 있는 생성형 AI 기술을 꾸준히 개발해왔다”며 “국내 AI 생태계가 멀티모달 LLM으로 한층 확장되고 활성화되는 데에 하이퍼클로바X가 기여할 수 있기를 기대한다”고 말했다.
]]></body>
</wms_article_body>
<wms_article_summary>
<summary><![CDATA[4월 개방한 ‘하이퍼클로바 X 시드 3B’ 국내 멀티모달 모델 중 최초로 깃허브 ‘vLLM 프로젝트’ 공식 지원 등재 글로벌 개발자 플랫폼에서 기술력 입증네이버가 지난 4월 오픈소스로 공개한 경량 멀티모달 인공지능(AI) 모델 ‘하이퍼클로바 X 시드 3B’가 글로벌 무대에서 존재감을 각인시키고 있다. 최근에는 전 세계 개발자들의 ‘즐겨찾기’로 통하는 깃허브]]></summary>
</wms_article_summary>
<stock_codes>
</stock_codes>
<wms_article_keywords>
</wms_article_keywords>
<wms_code_classes>
<wms_code_class>
<code_id>MK101507</code_id>
<code_nm><![CDATA[인공지능]]></code_nm>
<large_code_id>0</large_code_id>
<large_code_nm><![CDATA[뉴스]]></large_code_nm>
<middle_code_id>00559</middle_code_id>
<middle_code_nm><![CDATA[IT·과학]]></middle_code_nm>
<small_code_id>MK101507</small_code_id>
<small_code_nm><![CDATA[인공지능]]></small_code_nm>
</wms_code_class>
</wms_code_classes>
<wms_article_images>
<wms_article_image>
<image_url><![CDATA[https://wimg.mk.co.kr/news/cms/202508/14/news-p.v1.20250808.b5418fd784c9474c8626463e534f6c7d_P1.jpeg]]></image_url>
<image_caption><![CDATA[ [사진 = 네이버]]]></image_caption>
</wms_article_image>
<wms_article_image>
<image_url><![CDATA[https://wimg.mk.co.kr/news/cms/202508/14/news-p.v1.20250808.defaf1ce428c40a4b992f734ddb40de8_P1.png]]></image_url>
<image_caption><![CDATA[ 깃허브 vLLM 공식 지원 공지 [사진 = 네이버]]]></image_caption>
</wms_article_image>
</wms_article_images>
<article_url><![CDATA[https://www.mk.co.kr/article/11393858]]></article_url>
</article>
</saltlux>
