<?xml version="1.0" encoding="utf-8" ?>
<saltlux>
<article>
<action>T</action>
<wms_article>
<art_id>11390801</art_id>
<art_year>2025</art_year>
<art_no>572416</art_no>
<gubun>D</gubun>
<service_daytime>2025-08-11 16:10:20</service_daytime>
<title><![CDATA["가짜 영상 꼼짝마"…'토종 딥페이크 탐지' 맹활약]]></title>
<sub_title><![CDATA[한국전자기술연구원 '아이기스'<br>지난 대선 조작 영상 1만여건 탐지<br>3명 고발 '부정선거운동죄' 적용<br>국과수·경찰대와 협력 수사 실증<br>"플랫폼 딥페이크 방지 의무화<br>새로운 보안시장 열릴 것"]]></sub_title>
<media_code>01</media_code>
<writers><![CDATA[이윤식 기자(leeyunsik@mk.co.kr)]]></writers>
<free_type>F</free_type>
<pub_div>P</pub_div>
<pub_date>20250812</pub_date>
<pub_edition>11</pub_edition>
<pub_section>03</pub_section>
<pub_page>1</pub_page>
<reg_dt>2025-08-11 16:10:20</reg_dt>
<mod_dt></mod_dt>
<art_org_class>MK300105</art_org_class>
</wms_article>
<wms_article_body>
<body><![CDATA[<img src='https://wimg.mk.co.kr/news/cms/202508/12/20250812_01110301000002_L00.jpg' alt='한국전자기술연구원(KETI)이 개발한 딥페이크 콘텐츠 탐지 플랫폼 '아이기스'를 통해 딥페이크 영상을 분석한 모습. 해당 영상은 입 다물고 있는 백인 여성 사진을 이용해 AI 영상 제작 플랫폼 KLING 1.6을 통해 만들어졌다. 영상의 색이 붉은 색에 가까울 수록 아이기스가 집중해서 분석했음을 의미한다. 아이기스는 "이 부위의 움직임이 비정상적으로 부드럽다"는 식으로 가짜로 판명한 이유로 영문으로 설명한다.  KETI'>

최근 방문한 경기 성남 글로벌 R&D센터의 한국전자기술연구원(KETI) 지능형 영상처리연구센터. 젊은 백인 여성이 노래하는 5초 분량의 영상을 인공지능(AI) 기반 딥페이크 탐지 플랫폼 '아이기스'에 입력하자 Fake(가짜) 지수가 100점 만점에 95.8080으로 나타나 해당 영상을 가짜로 판정했다. 이 수치는 0에 가까울수록 리얼(진짜), 100에 가까울수록 페이크(가짜)를 의미한다. 해당 영상은 올해 출시된 영상 생성 AI 툴 'KLING AI 1.6'에 백인 여성 사진 한 장을 넣어 만든 딥페이크 콘텐츠였다.
아이기스는 영상에서 대표 프레임을 추출한 뒤 눈가와 입술 주변 주름 등 조작이 의심되는 부위를 열화상 이미지처럼 붉은색으로 시각화해 표시했다. 또 "부위의 움직임이 비정상적으로 부드럽다"는 식으로 해당 영상을 딥페이크로 판단한 이유를 영문 문장으로 제공했다.
그렇다면 포토샵으로 보정한 사진은 진짜일까, 가짜일까. 기자의 얼굴 사진을 아이기스로 분석한 결과 한 번은 진짜로, 또 다른 한 번은 가짜로 판정됐다. 아이기스는 머리 전체, 입술 중심 등 총 5가지 분석 방식을 제공하는데 어떤 기능을 활성화하느냐에 따라 결과가 달라지는 것이다.
아이기스는 KETI가 과학기술정보통신부와 정보통신기획평가원(IITP) 지원을 받아 개발한 토종 딥페이크 탐지 플랫폼이다. 고대 그리스 신화 속 제우스의 방패 'AEGIS'에서 이름을 따 와서 어떤 딥페이크 영상이라도 가짜 여부를 판별해 관련 범죄를 예방하겠다는 뜻을 담았다. 조충상 KETI 책임연구원(박사)은 "포토샵에 다양한 기능이 있는 것처럼 아이기스도 분석 기능이 다양하다"며 "이를 조합하면 정교하게 설계된 딥페이크 영상을 판독할 수 있다"고 설명했다.
아이기스는 KETI가 자체 개발한 AI 엔진 'XAI'를 기반으로 구동된다. 딥러닝 기반 노이즈 제거 알고리즘을 역방향으로 적용해 조작된 콘텐츠에 내재된 비정상 신호를 탐지하는 방식이다. 최초 개발에 사용된 학습 데이터는 5~10초짜리 영상 2만건으로, 다른 AI 툴에 비해 상대적으로 적다. 조 책임연구원은 "일부 해외 플랫폼은 포르노 사이트에서 딥페이크 영상을 대량 크롤링해 학습에 활용하지만, 국내에서는 법적·윤리적 제약이 크다"며 "아이기스는 적은 데이터로도 높은 정확도를 구현하도록 설계됐고, 과거 데이터를 잊지 않고 새로운 패턴을 반영할 수 있는 구조가 핵심"이라고 밝혔다.
중앙선거관리위원회는 올해 제21대 대통령 선거 기간에 아이기스를 활용해 영상·이미지·오디오 등 딥페이크 콘텐츠 1만510건에 대해 삭제를 요청했다. 또 선관위는 의도성 등이 심각한 3건의 딥페이크 콘텐츠 제작자 3명을 공직선거법 위반 혐의로 고발했다.
특히 이번 고발은 2023년 공직선거법에 딥페이크 관련 조항이 도입된 후 처음 적용된 사례로 주목받았다. 공직선거법 82조의 8은 "선거일 전 90일부터 선거일까지 선거운동을 위하여 인공지능 기술 등을 이용하여 만든 실제와 구분하기 어려운 가상의 음향, 이미지 또는 영상 등을 제작·편집·유포·상영 또는 게시하는 행위를 하여서는 아니 된다"고 규정한다. 또 같은 법 255조는 딥페이크 콘텐츠로 부정 선거운동을 하면 7년 이하의 징역 또는 1000만원 이상 5000만원 이하의 벌금에 처하도록 했다.
이번 대선에서 선관위가 고발한 딥페이크 콘텐츠는 △특정 인터넷 커뮤니티 게시판에 대선 후보자가 죄수복을 입고 감옥에 수감된 이미지 등 △유튜브 채널 내 AI로 구현된 여성 아나운서를 이용해 뉴스 형식으로 후보자의 당선·낙선을 도모하는 영상을 제작·게시 △개인 사회관계망서비스(SNS)에 특정 후보자에 대한 부정적인 이미지를 주는 글과 영상을 딥페이크로 직접 제작·게시한 사례였다.
이런 사례 중 하나를 보면 영상 앞뒤는 진짜로 분석됐지만, 중간에 조작된 영상을 교묘하게 삽입한 콘텐츠였다. 탐지 과정에서 해당 구간만 가짜로 표시되자, 분석팀은 조작된 부분을 잘라 다시 입력했고 그 결과 명확히 가짜로 판정받았다. 조 책임연구원은 "의도적으로 메시지를 왜곡한 콘텐츠는 중대한 조작"이라며 "선관위가 고발까지 간 것도 그런 의도성 때문"이라고 설명했다.
아이기스 개발팀은 실제 딥페이크 제작 도구를 활용하는 '공격팀'과 이를 탐지하는 '방어팀'으로 나뉘어 반복 실험과 학습을 진행했다. 선거 기간 선관위에서 받은 기능 보완 요청을 반영해 3~4일 간격으로 업데이트를 진행했고, 약 48일 동안 실제 딥페이크를 탐지하며 고도화됐다.
조 책임연구원은 "결국 국내 보안 솔루션을 개발하는 중소기업이 많은 상황 속에서 딥페이크와 딥페이크 탐지 기술은 궁극적으로 보안산업 자체의 새로운 섹터를 열 것"이라며 "앞으로 국내 보안 산업의 중소기업들은 이러한 부분에서 새로운 기회를 찾을 수 있을 것"이라고 말했다.
앞으로 아이기스는 선거 외에도 국립과학수사연구원, 경찰대학 등과 협력해 수사·치안 분야에서도 실증을 확대할 계획이다. 신희동 KETI 원장은 "KETI는 세계 최고 수준의 자기 진화형 딥페이크 탐지 기술 개발을 목표로 연구 역량을 집중하고 있다"며 "허위 정보로 인한 사회적 혼란과 비용을 줄이는 데 이바지하겠다"고 밝혔다.  
[이윤식 기자]]]></body>
</wms_article_body>
<wms_article_summary>
<summary><![CDATA[최근 방문한 경기 성남 글로벌 R&D센터의 한국전자기술연구원(KETI) 지능형 영상처리연구센터. 젊은 백인 여성이 노래하는 5초 분량의 영상을 인공지능(AI) 기반 딥페이크 탐지 플랫폼 '아이기스'에 입력하자 Fake(가짜) 지수가 100점 만점에 95.8080으로 나타나 해당 영상을 가짜로 판정했다. 이 수치는 0에 가까울수록 리얼(진짜), 100에 가까울수록 페이크(가짜)를 의미한다. 해당 영상은 올해 출시된 영상 생성 AI 툴 'KLING AI 1]]></summary>
</wms_article_summary>
<stock_codes>
</stock_codes>
<wms_article_keywords>
</wms_article_keywords>
<wms_code_classes>
<wms_code_class>
<code_id>MK300105</code_id>
<code_nm><![CDATA[중소기업 Mart]]></code_nm>
<large_code_id>0</large_code_id>
<large_code_nm><![CDATA[뉴스]]></large_code_nm>
<middle_code_id>00501</middle_code_id>
<middle_code_nm><![CDATA[기업]]></middle_code_nm>
<small_code_id>MK300105</small_code_id>
<small_code_nm><![CDATA[중소기업 Mart]]></small_code_nm>
</wms_code_class>
</wms_code_classes>
<wms_article_images>
<wms_article_image>
<image_url><![CDATA[https://wimg.mk.co.kr/news/cms/202508/12/20250812_01110301000002_L00.jpg]]></image_url>
<image_caption><![CDATA[한국전자기술연구원(KETI)이 개발한 딥페이크 콘텐츠 탐지 플랫폼 '아이기스'를 통해 딥페이크 영상을 분석한 모습. 해당 영상은 입 다물고 있는 백인 여성 사진을 이용해 AI 영상 제작 플랫폼 KLING 1.6을 통해 만들어졌다. 영상의 색이 붉은 색에 가까울 수록 아이기스가 집중해서 분석했음을 의미한다. 아이기스는 "이 부위의 움직임이 비정상적으로 부드럽다"는 식으로 가짜로 판명한 이유로 영문으로 설명한다.  KETI]]></image_caption>
</wms_article_image>
</wms_article_images>
<article_url><![CDATA[https://www.mk.co.kr/article/11390801]]></article_url>
</article>
</saltlux>
