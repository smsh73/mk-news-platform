"""
FastAPI ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ - ë§¤ì¼ê²½ì œ ì‹ ë¬¸ê¸°ì‚¬ ë²¡í„°ì„ë² ë”© í”Œë«í¼
"""
import os
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from pathlib import Path
import uvicorn
import subprocess
import threading
import json

from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, UploadFile, File
from fastapi.responses import StreamingResponse
# from .terraform_manager import get_terraform_manager
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# Jinja2TemplatesëŠ” ì„ íƒì ìœ¼ë¡œ import
try:
    from fastapi.templating import Jinja2Templates
except ImportError:
    Jinja2Templates = None

from ..database.connection import get_db, init_database
from ..database.models import Article, VectorIndex, ProcessingLog
from ..xml_processor import XMLProcessor
from ..vector_search.vector_indexer import VectorIndexer
from ..rag.hybrid_rag_system import HybridRAGSystem
from ..incremental.incremental_processor import IncrementalProcessor
from ..embedding.embedding_service import EmbeddingService
from .docker_build import get_docker_builder
from ..ftp import get_ftp_client
from ..ftp.ftp_pipeline import FTPPipeline
from ..storage.gcs_client import GCSClient
from ..auth import authenticate_user, create_access_token, get_current_user, verify_token

logger = logging.getLogger(__name__)

# FTP í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ (ì „ì—­)
ftp_client_instance = None

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="ë§¤ì¼ê²½ì œ ì‹ ë¬¸ê¸°ì‚¬ ë²¡í„°ì„ë² ë”© í”Œë«í¼",
    description="GCP VertexAI ê¸°ë°˜ ì‹ ë¬¸ê¸°ì‚¬ ë²¡í„°ì„ë² ë”© ë° Hybrid RAG ì‹œìŠ¤í…œ",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ë° í…œí”Œë¦¿ ì„¤ì •
# staticê³¼ templates ë””ë ‰í† ë¦¬ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ë§ˆìš´íŠ¸
static_path = os.path.join(os.path.dirname(__file__), "static")
if os.path.exists(static_path):
    # React ë¹Œë“œ ê²°ê³¼ë¬¼ì˜ ì‹¤ì œ ì •ì  íŒŒì¼ ê²½ë¡œ
    static_assets_path = os.path.join(static_path, "static")
    if os.path.exists(static_assets_path):
        app.mount("/static", StaticFiles(directory=static_assets_path), name="static")
    else:
        app.mount("/static", StaticFiles(directory=static_path), name="static")
if os.path.exists("templates") and Jinja2Templates is not None:
    templates = Jinja2Templates(directory="templates")
else:
    templates = None

# ì „ì—­ ë³€ìˆ˜
project_id = os.getenv('GCP_PROJECT_ID', 'mk-ai-project-473000')
region = os.getenv('GCP_REGION', 'asia-northeast3')

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (í…ŒìŠ¤íŠ¸ ëª¨ë“œ)
xml_processor = XMLProcessor()
# GCP ì„œë¹„ìŠ¤ëŠ” í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œ ë¹„í™œì„±í™”
try:
    vector_indexer = VectorIndexer(project_id, region)
    rag_system = HybridRAGSystem(project_id, region)
    incremental_processor = IncrementalProcessor(project_id, region)
except Exception as e:
    print(f"GCP ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ): {e}")
    vector_indexer = None
    rag_system = None
    incremental_processor = None

embedding_service = EmbeddingService()

# Pydantic ëª¨ë¸
class LoginRequest(BaseModel):
    username: str
    password: str

class QueryRequest(BaseModel):
    query: str
    filters: Optional[Dict] = None
    top_k: int = 10
    similarity_threshold: float = 0.7
    max_context_length: int = 4000
    weights: Optional[Dict] = None

class ProcessXMLRequest(BaseModel):
    xml_directory: str
    batch_size: int = 100
    max_workers: int = 4
    embedding_model: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

class AnalysisRequest(BaseModel):
    article_id: int
    timeline_years: int = 3
    analysis_depth: str = "ìƒì„¸"
    include_timeline: bool = True
    include_current: bool = True
    include_future: bool = True

class VectorIndexRequest(BaseModel):
    index_name: str = "mk-news-vector-index"
    dimensions: int = 768
    description: str = "ë§¤ì¼ê²½ì œ ì‹ ë¬¸ê¸°ì‚¬ ë²¡í„° ì¸ë±ìŠ¤"

class ProcessRequest(BaseModel):
    xml_directory: str
    batch_size: int = 100

class IncrementalProcessRequest(BaseModel):
    xml_directory: str
    last_processed_time: Optional[str] = None

# API ì—”ë“œí¬ì¸íŠ¸
@app.get("/", response_class=HTMLResponse)
async def root():
    """React ì•± ë©”ì¸ í˜ì´ì§€"""
    static_path = os.path.join(os.path.dirname(__file__), "static")
    index_path = os.path.join(static_path, "index.html")
    
    if os.path.exists(index_path):
        with open(index_path, "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    else:
        return HTMLResponse(content="""
        <!DOCTYPE html>
        <html>
        <head>
            <title>ë§¤ì¼ê²½ì œ AI í”Œë«í¼</title>
        </head>
        <body>
            <h1>ë§¤ì¼ê²½ì œ ì‹ ë¬¸ê¸°ì‚¬ ë²¡í„°ì„ë² ë”© í”Œë«í¼ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!</h1>
            <p>React ì•±ì´ ì•„ì§ ë¹Œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.</p>
        </body>
        </html>
        """)

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0"
    }

@app.post("/api/auth/login")
async def login(login_request: LoginRequest):
    """ì‚¬ìš©ì ë¡œê·¸ì¸"""
    try:
        if authenticate_user(login_request.username, login_request.password):
            access_token = create_access_token(data={"sub": login_request.username})
            return {
                "success": True,
                "token": access_token,
                "message": "ë¡œê·¸ì¸ ì„±ê³µ"
            }
        else:
            raise HTTPException(
                status_code=401,
                detail="ì‚¬ìš©ìëª… ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )
    except Exception as e:
        logger.error(f"ë¡œê·¸ì¸ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ë¡œê·¸ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.get("/api/auth/verify")
async def verify_token_endpoint(current_user: dict = Depends(get_current_user)):
    """í† í° ê²€ì¦"""
    return {
        "success": True,
        "username": current_user.get("username"),
        "message": "ì¸ì¦ëœ ì‚¬ìš©ìì…ë‹ˆë‹¤."
    }

@app.post("/api/process-xml")
async def process_xml_files(request: ProcessRequest, background_tasks: BackgroundTasks):
    """XML íŒŒì¼ ì²˜ë¦¬"""
    try:
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
        background_tasks.add_task(
            xml_processor.process_xml_files,
            request.xml_directory,
            request.batch_size
        )
        
        return {
            "status": "processing",
            "message": "XML íŒŒì¼ ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "xml_directory": request.xml_directory
        }
        
    except Exception as e:
        logger.error(f"XML íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/incremental-process")
async def incremental_process(request: IncrementalProcessRequest, background_tasks: BackgroundTasks):
    """ì¦ë¶„í˜• ì²˜ë¦¬"""
    try:
        last_processed_time = None
        if request.last_processed_time:
            last_processed_time = datetime.fromisoformat(request.last_processed_time)
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
        background_tasks.add_task(
            incremental_processor.process_incremental_articles,
            request.xml_directory,
            last_processed_time
        )
        
        return {
            "status": "processing",
            "message": "ì¦ë¶„í˜• ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "xml_directory": request.xml_directory
        }
        
    except Exception as e:
        logger.error(f"ì¦ë¶„í˜• ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/query")
async def query_articles(request: QueryRequest):
    """ê¸°ì‚¬ ê²€ìƒ‰ ë° ì§ˆì˜ì‘ë‹µ"""
    try:
        result = rag_system.process_query(
            query=request.query,
            filters=request.filters,
            top_k=request.top_k
        )
        
        return result
        
    except Exception as e:
        logger.error(f"ê¸°ì‚¬ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/stats")
async def get_system_stats():
    """ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ"""
    try:
        stats = rag_system.get_system_stats()
        return stats
        
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/articles")
async def get_articles(
    skip: int = 0,
    limit: int = 100,
    category: Optional[str] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
):
    """ê¸°ì‚¬ ëª©ë¡ ì¡°íšŒ"""
    try:
        db = next(get_db())
        try:
            query = db.query(Article).filter(Article.is_processed == True)
            
            # í•„í„° ì ìš©
            if category:
                query = query.filter(Article.art_org_class.contains(category))
            
            if start_date:
                start_dt = datetime.fromisoformat(start_date)
                query = query.filter(Article.service_daytime >= start_dt)
            
            if end_date:
                end_dt = datetime.fromisoformat(end_date)
                query = query.filter(Article.service_daytime <= end_dt)
            
            # í˜ì´ì§•
            articles = query.offset(skip).limit(limit).all()
            
            return [
                {
                    "id": article.id,
                    "art_id": article.art_id,
                    "title": article.title,
                    "summary": article.summary,
                    "service_daytime": article.service_daytime.isoformat() if article.service_daytime else None,
                    "article_url": article.article_url,
                    "is_embedded": article.is_embedded
                }
                for article in articles
            ]
            
        finally:
            db.close()
            
    except Exception as e:
        logger.error(f"ê¸°ì‚¬ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/articles/{article_id}")
async def get_article(article_id: str):
    """íŠ¹ì • ê¸°ì‚¬ ì¡°íšŒ"""
    try:
        db = next(get_db())
        try:
            article = db.query(Article).filter(Article.id == article_id).first()
            
            if not article:
                raise HTTPException(status_code=404, detail="ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            return {
                "id": article.id,
                "art_id": article.art_id,
                "title": article.title,
                "body": article.body,
                "summary": article.summary,
                "writers": article.writers,
                "service_daytime": article.service_daytime.isoformat() if article.service_daytime else None,
                "article_url": article.article_url,
                "is_embedded": article.is_embedded,
                "created_at": article.created_at.isoformat()
            }
            
        finally:
            db.close()
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ê¸°ì‚¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/vector-index/status")
async def get_vector_index_status():
    """ë²¡í„° ì¸ë±ìŠ¤ ìƒíƒœ ì¡°íšŒ"""
    try:
        if not vector_indexer:
            return {'status': 'not_initialized', 'message': 'Vector indexerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}
        
        status = vector_indexer.get_index_status()
        return status
        
    except Exception as e:
        logger.error(f"ë²¡í„° ì¸ë±ìŠ¤ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/vector-index/create")
async def create_vector_index():
    """ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±"""
    try:
        result = vector_indexer.create_vector_index()
        return result
        
    except Exception as e:
        logger.error(f"ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/vector-index/deploy")
async def deploy_vector_index():
    """ë²¡í„° ì¸ë±ìŠ¤ ë°°í¬"""
    try:
        result = vector_indexer.deploy_index()
        return result
        
    except Exception as e:
        logger.error(f"ë²¡í„° ì¸ë±ìŠ¤ ë°°í¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/vector-index/update")
async def update_vector_index(background_tasks: BackgroundTasks):
    """ë²¡í„° ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸"""
    try:
        background_tasks.add_task(vector_indexer.index_articles)
        
        return {
            "status": "processing",
            "message": "ë²¡í„° ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
    except Exception as e:
        logger.error(f"ë²¡í„° ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/processing-logs")
async def get_processing_logs(
    skip: int = 0,
    limit: int = 100,
    process_type: Optional[str] = None
):
    """ì²˜ë¦¬ ë¡œê·¸ ì¡°íšŒ"""
    try:
        db = next(get_db())
        try:
            query = db.query(ProcessingLog)
            
            if process_type:
                query = query.filter(ProcessingLog.process_type == process_type)
            
            logs = query.order_by(ProcessingLog.created_at.desc()).offset(skip).limit(limit).all()
            
            return [
                {
                    "id": log.id,
                    "article_id": log.article_id,
                    "process_type": log.process_type,
                    "status": log.status,
                    "message": log.message,
                    "processing_time": log.processing_time,
                    "created_at": log.created_at.isoformat()
                }
                for log in logs
            ]
            
        finally:
            db.close()
            
    except Exception as e:
        logger.error(f"ì²˜ë¦¬ ë¡œê·¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/duplicate-cleanup")
async def cleanup_duplicates():
    """ì¤‘ë³µ ê¸°ì‚¬ ì •ë¦¬"""
    try:
        result = incremental_processor.cleanup_duplicates()
        return result
        
    except Exception as e:
        logger.error(f"ì¤‘ë³µ ê¸°ì‚¬ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ê´€ë¦¬ì í™”ë©´ ë¼ìš°íŠ¸
@app.get("/admin", response_class=HTMLResponse)
async def admin_dashboard():
    """ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ"""
    return """
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>ë§¤ì¼ê²½ì œ ì‹ ë¬¸ê¸°ì‚¬ ë²¡í„°ì„ë² ë”© í”Œë«í¼ - ê´€ë¦¬ì</title>
        <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
        <style>
            body { font-family: Arial, sans-serif; margin: 0; padding: 20px; background-color: #f5f5f5; }
            .container { max-width: 1200px; margin: 0 auto; }
            .header { background: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
            .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }
            .card { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
            .btn { background: #007bff; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; margin: 5px; }
            .btn:hover { background: #0056b3; }
            .btn-danger { background: #dc3545; }
            .btn-success { background: #28a745; }
            .status { padding: 5px 10px; border-radius: 4px; color: white; font-size: 12px; }
            .status-success { background: #28a745; }
            .status-error { background: #dc3545; }
            .status-warning { background: #ffc107; color: black; }
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ë§¤ì¼ê²½ì œ ì‹ ë¬¸ê¸°ì‚¬ ë²¡í„°ì„ë² ë”© í”Œë«í¼</h1>
                <p>ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ</p>
            </div>
            
            <div class="grid">
                <div class="card">
                    <h3>ì‹œìŠ¤í…œ í†µê³„</h3>
                    <div id="stats">
                        <p>ë¡œë”© ì¤‘...</p>
                    </div>
                </div>
                
                <div class="card">
                    <h3>ë²¡í„° ì¸ë±ìŠ¤ ìƒíƒœ</h3>
                    <div id="index-status">
                        <p>ë¡œë”© ì¤‘...</p>
                    </div>
                </div>
                
                <div class="card">
                    <h3>ì²˜ë¦¬ ì‘ì—…</h3>
                    <button class="btn btn-success" onclick="processXML()">XML ì²˜ë¦¬</button>
                    <button class="btn btn-success" onclick="incrementalProcess()">ì¦ë¶„í˜• ì²˜ë¦¬</button>
                    <button class="btn" onclick="updateIndex()">ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸</button>
                    <button class="btn btn-danger" onclick="cleanupDuplicates()">ì¤‘ë³µ ì •ë¦¬</button>
                </div>
                
                <div class="card">
                    <h3>ìµœê·¼ ì²˜ë¦¬ ë¡œê·¸</h3>
                    <div id="logs">
                        <p>ë¡œë”© ì¤‘...</p>
                    </div>
                </div>
            </div>
        </div>
        
        <script>
            // ì‹œìŠ¤í…œ í†µê³„ ë¡œë“œ
            async function loadStats() {
                try {
                    const response = await fetch('/api/stats');
                    const stats = await response.json();
                    
                    document.getElementById('stats').innerHTML = `
                        <p><strong>ì´ ê¸°ì‚¬:</strong> ${stats.total_articles || 0}</p>
                        <p><strong>ì²˜ë¦¬ëœ ê¸°ì‚¬:</strong> ${stats.processed_articles || 0}</p>
                        <p><strong>ì„ë² ë”©ëœ ê¸°ì‚¬:</strong> ${stats.embedded_articles || 0}</p>
                        <p><strong>ìµœê·¼ ê¸°ì‚¬:</strong> ${stats.recent_articles || 0}</p>
                        <p><strong>ì¹´í…Œê³ ë¦¬:</strong> ${stats.categories || 0}</p>
                    `;
                } catch (error) {
                    document.getElementById('stats').innerHTML = '<p>í†µê³„ ë¡œë“œ ì‹¤íŒ¨</p>';
                }
            }
            
            // ë²¡í„° ì¸ë±ìŠ¤ ìƒíƒœ ë¡œë“œ
            async function loadIndexStatus() {
                try {
                    const response = await fetch('/api/vector-index/status');
                    const status = await response.json();
                    
                    document.getElementById('index-status').innerHTML = `
                        <p><strong>ìƒíƒœ:</strong> <span class="status status-success">${status.status || 'Unknown'}</span></p>
                        <p><strong>ì¸ë±ìŠ¤ ID:</strong> ${status.index_id || 'N/A'}</p>
                        <p><strong>ì—”ë“œí¬ì¸íŠ¸ ID:</strong> ${status.endpoint_id || 'N/A'}</p>
                    `;
                } catch (error) {
                    document.getElementById('index-status').innerHTML = '<p>ì¸ë±ìŠ¤ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨</p>';
                }
            }
            
            // ì²˜ë¦¬ ë¡œê·¸ ë¡œë“œ
            async function loadLogs() {
                try {
                    const response = await fetch('/api/processing-logs?limit=10');
                    const logs = await response.json();
                    
                    const logsHtml = logs.map(log => `
                        <div style="border-bottom: 1px solid #eee; padding: 10px 0;">
                            <p><strong>${log.process_type}</strong> - ${log.status}</p>
                            <p style="font-size: 12px; color: #666;">${log.message}</p>
                            <p style="font-size: 12px; color: #999;">${log.created_at}</p>
                        </div>
                    `).join('');
                    
                    document.getElementById('logs').innerHTML = logsHtml || '<p>ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.</p>';
                } catch (error) {
                    document.getElementById('logs').innerHTML = '<p>ë¡œê·¸ ë¡œë“œ ì‹¤íŒ¨</p>';
                }
            }
            
            // XML ì²˜ë¦¬
            async function processXML() {
                try {
                    const response = await fetch('/api/process-xml', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ xml_directory: '/path/to/xml/files', batch_size: 100 })
                    });
                    const result = await response.json();
                    alert('XML ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.');
                } catch (error) {
                    alert('XML ì²˜ë¦¬ ì‹œì‘ ì‹¤íŒ¨: ' + error.message);
                }
            }
            
            // ì¦ë¶„í˜• ì²˜ë¦¬
            async function incrementalProcess() {
                try {
                    const response = await fetch('/api/incremental-process', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ xml_directory: '/path/to/xml/files' })
                    });
                    const result = await response.json();
                    alert('ì¦ë¶„í˜• ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.');
                } catch (error) {
                    alert('ì¦ë¶„í˜• ì²˜ë¦¬ ì‹œì‘ ì‹¤íŒ¨: ' + error.message);
                }
            }
            
            // ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
            async function updateIndex() {
                try {
                    const response = await fetch('/api/vector-index/update', { method: 'POST' });
                    const result = await response.json();
                    alert('ë²¡í„° ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.');
                } catch (error) {
                    alert('ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì‹œì‘ ì‹¤íŒ¨: ' + error.message);
                }
            }
            
            // ì¤‘ë³µ ì •ë¦¬
            async function cleanupDuplicates() {
                try {
                    const response = await fetch('/api/duplicate-cleanup');
                    const result = await response.json();
                    alert(result.message || 'ì¤‘ë³µ ì •ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.');
                } catch (error) {
                    alert('ì¤‘ë³µ ì •ë¦¬ ì‹¤íŒ¨: ' + error.message);
                }
            }
            
            // í˜ì´ì§€ ë¡œë“œ ì‹œ ë°ì´í„° ë¡œë“œ
            window.onload = function() {
                loadStats();
                loadIndexStatus();
                loadLogs();
                
                // 30ì´ˆë§ˆë‹¤ ë°ì´í„° ìƒˆë¡œê³ ì¹¨
                setInterval(() => {
                    loadStats();
                    loadIndexStatus();
                    loadLogs();
                }, 30000);
            };
        </script>
    </body>
    </html>
    """

# ìƒˆë¡œìš´ ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.post("/api/query")
async def query_articles(request: QueryRequest):
    """RAG ì‹œìŠ¤í…œ ì¿¼ë¦¬ (ê°€ì¤‘ì¹˜ ë° ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì§€ì›)"""
    try:
        # RAG ì‹œìŠ¤í…œìœ¼ë¡œ ì¿¼ë¦¬ ì²˜ë¦¬
        result = rag_system.process_query(
            query=request.query,
            filters=request.filters,
            top_k=request.top_k,
            similarity_threshold=request.similarity_threshold,
            max_context_length=request.max_context_length,
            weights=request.weights
        )
        
        return result
        
    except Exception as e:
        logger.error(f"ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/process-xml")
async def process_xml(request: ProcessXMLRequest, background_tasks: BackgroundTasks):
    """XML íŒŒì¼ ë²¡í„°ì„ë² ë”© ë°°ì¹˜ ì²˜ë¦¬"""
    try:
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ XML ì²˜ë¦¬ ì‹œì‘
        background_tasks.add_task(
            xml_processor.process_xml_files,
            request.xml_directory,
            request.batch_size,
            request.max_workers,
            request.embedding_model
        )
        
        return {
            "message": "XML ë²¡í„°ì„ë² ë”© ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "xml_directory": request.xml_directory,
            "batch_size": request.batch_size,
            "max_workers": request.max_workers,
            "embedding_model": request.embedding_model
        }
    except Exception as e:
        logger.error(f"XML ì²˜ë¦¬ ì‹œì‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="XML ì²˜ë¦¬ ì‹œì‘ ì‹¤íŒ¨")

@app.post("/api/extract-metadata")
async def extract_metadata(background_tasks: BackgroundTasks):
    """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    try:
        background_tasks.add_task(xml_processor.extract_metadata)
        
        return {
            "message": "ë©”íƒ€ë°ì´í„° ì¶”ì¶œì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")

@app.post("/api/index-metadata")
async def index_metadata(background_tasks: BackgroundTasks):
    """ë©”íƒ€ë°ì´í„° ì¸ë±ì‹±"""
    try:
        background_tasks.add_task(xml_processor.index_metadata)
        
        return {
            "message": "ë©”íƒ€ë°ì´í„° ì¸ë±ì‹±ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ë©”íƒ€ë°ì´í„° ì¸ë±ì‹± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ë©”íƒ€ë°ì´í„° ì¸ë±ì‹± ì‹¤íŒ¨")

@app.get("/api/processing-stats")
async def get_processing_stats(db = Depends(get_db)):
    """ì²˜ë¦¬ í†µê³„ ì¡°íšŒ"""
    try:
        total_processed = db.query(Article).filter(Article.is_processed == True).count()
        embedded_count = db.query(Article).filter(Article.is_embedded == True).count()
        metadata_extracted = db.query(Article).filter(Article.is_processed == True).count()
        indexed_count = db.query(Article).filter(Article.is_embedded == True).count()
        
        return {
            "total_processed": total_processed,
            "embedded_count": embedded_count,
            "metadata_extracted": metadata_extracted,
            "indexed_count": indexed_count,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ì²˜ë¦¬ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ì²˜ë¦¬ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨")

@app.post("/api/generate-analysis")
async def generate_analysis(request: AnalysisRequest):
    """ê°œë³„ ê¸°ì‚¬ í•´ì„¤ ìƒì„±"""
    try:
        # ê¸°ì‚¬ ì •ë³´ ì¡°íšŒ
        db = next(get_db())
        article = db.query(Article).filter(Article.id == request.article_id).first()
        if not article:
            raise HTTPException(status_code=404, detail="ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # í•´ì„¤ ìƒì„± (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” rag_systemì˜ ë©”ì„œë“œ í˜¸ì¶œ)
        analysis_result = {
            "article_id": request.article_id,
            "timeline_analysis": f"{request.timeline_years}ë…„ê°„ì˜ ê´€ë ¨ ê¸°ì‚¬ íƒ€ì„ë¼ì¸ ë¶„ì„ ê²°ê³¼",
            "current_analysis": "í˜„ì¬ ê¸°ì‚¬ì˜ ë…¼ì„¤ ë° ì£¼ìš” ë‚´ìš© ë¶„ì„",
            "future_analysis": "í–¥í›„ ì „ë§ ë° ì¶”ì´ ë¶„ì„",
            "reference_articles": [],
            "processing_time": 2.5,
            "analysis_depth": request.analysis_depth
        }
        
        return analysis_result
    except Exception as e:
        logger.error(f"í•´ì„¤ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="í•´ì„¤ ìƒì„± ì‹¤íŒ¨")

@app.get("/api/analysis-history")
async def get_analysis_history(limit: int = 10, db = Depends(get_db)):
    """í•´ì„¤ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    try:
        # ì‹¤ì œë¡œëŠ” ë³„ë„ì˜ AnalysisHistory í…Œì´ë¸”ì´ í•„ìš”í•˜ì§€ë§Œ, 
        # ì—¬ê¸°ì„œëŠ” ProcessingLogë¥¼ í™œìš©
        logs = db.query(ProcessingLog).filter(
            ProcessingLog.process_type == "analysis"
        ).order_by(ProcessingLog.created_at.desc()).limit(limit).all()
        
        history = []
        for log in logs:
            history.append({
                "article_id": log.article_id,
                "article_title": "N/A",  # ì‹¤ì œë¡œëŠ” Article í…Œì´ë¸”ê³¼ ì¡°ì¸ í•„ìš”
                "analysis_type": log.process_type,
                "created_at": log.created_at.isoformat(),
                "processing_time": log.processing_time,
                "reference_count": 0  # ì‹¤ì œë¡œëŠ” ë³„ë„ ê³„ì‚° í•„ìš”
            })
        
        return history
    except Exception as e:
        logger.error(f"í•´ì„¤ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="í•´ì„¤ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨")

@app.get("/api/search-history")
async def get_search_history(limit: int = 10, db = Depends(get_db)):
    """ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    try:
        # ì‹¤ì œë¡œëŠ” ë³„ë„ì˜ SearchHistory í…Œì´ë¸”ì´ í•„ìš”
        logs = db.query(ProcessingLog).filter(
            ProcessingLog.process_type == "search"
        ).order_by(ProcessingLog.created_at.desc()).limit(limit).all()
        
        history = []
        for log in logs:
            history.append({
                "query": log.message,  # ì‹¤ì œë¡œëŠ” ë³„ë„ í•„ë“œ í•„ìš”
                "created_at": log.created_at.isoformat(),
                "result_count": 0,  # ì‹¤ì œë¡œëŠ” ë³„ë„ ê³„ì‚° í•„ìš”
                "processing_time": log.processing_time,
                "filters": {}  # ì‹¤ì œë¡œëŠ” ë³„ë„ í•„ë“œ í•„ìš”
            })
        
        return history
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨")

# ========================================
# Terraform ê´€ë¦¬ API
# ========================================

@app.get("/api/terraform/status")
async def get_terraform_status():
    """Terraform ìƒíƒœ ì¡°íšŒ"""
    # manager = get_terraform_manager()
    # return manager.get_workspace_info()
    return {"status": "disabled", "message": "Terraform manager temporarily disabled"}

@app.post("/api/terraform/init")
async def terraform_init(request: dict = None):
    """Terraform ì´ˆê¸°í™”"""
    try:
        # í”„ë¡œì íŠ¸ ID ë°›ê¸°
        project_id = request.get('project_id') if request else None
        
        # í”„ë¡œì íŠ¸ IDê°€ ì—†ìœ¼ë©´ gcloudì—ì„œ ê°€ì ¸ì˜¤ê¸°
        if not project_id:
            try:
                result = subprocess.run(['gcloud', 'config', 'get-value', 'project'], 
                                      capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    project_id = result.stdout.strip()
                    logger.info(f"gcloudì—ì„œ í”„ë¡œì íŠ¸ ID ê°€ì ¸ì˜´: {project_id}")
            except Exception as e:
                logger.error(f"gcloud í”„ë¡œì íŠ¸ ID ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        
        # terraform.tfvars íŒŒì¼ ìë™ ìƒì„±
        if project_id:
            tfvars_content = f'''project_id = "{project_id}"
region     = "asia-northeast3"
zone       = "asia-northeast3-a"
'''
            tfvars_path = 'terraform/terraform.tfvars'
            with open(tfvars_path, 'w', encoding='utf-8') as f:
                f.write(tfvars_content)
            logger.info(f"terraform.tfvars íŒŒì¼ ìƒì„± ì™„ë£Œ: project_id={project_id}")
        
        result = subprocess.run(['terraform', 'init'], cwd='terraform', 
                              capture_output=True, text=True, timeout=120)
        return {
            "success": result.returncode == 0,
            "logs": result.stdout.split('\n') + result.stderr.split('\n'),
            "status": "completed" if result.returncode == 0 else "error"
        }
    except Exception as e:
        return {"success": False, "error": str(e), "logs": []}

@app.post("/api/terraform/plan")
async def terraform_plan(request: dict = None):
    """Terraform Plan"""
    try:
        # terraform.tfvars íŒŒì¼ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì‚¬ìš©ë¨
        result = subprocess.run(['terraform', 'plan'], 
                              cwd='terraform', capture_output=True, text=True, timeout=300)
        return {
            "success": result.returncode == 0,
            "logs": result.stdout.split('\n') + result.stderr.split('\n'),
            "status": "completed" if result.returncode == 0 else "error"
        }
    except Exception as e:
        return {"success": False, "error": str(e), "logs": []}

@app.post("/api/docker/build")
async def build_docker_image(request: dict = None):
    """Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ"""
    try:
        builder = get_docker_builder()
        force_rebuild = request.get('force_rebuild', False) if request else False
        result = builder.build_and_push_admin_image(force_rebuild=force_rebuild)
        return result
    except Exception as e:
        return {"success": False, "error": str(e), "logs": []}

@app.post("/api/docker/check")
async def check_docker_image(request: dict = None):
    """Docker ì´ë¯¸ì§€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    try:
        builder = get_docker_builder()
        exists = builder.check_image_exists()
        return {"exists": exists}
    except Exception as e:
        return {"exists": False, "error": str(e)}

@app.post("/api/terraform/apply")
async def terraform_apply(request: dict = None):
    """
    Terraform Apply
    Docker ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ë¹Œë“œ
    """
    try:
        force_rebuild = request.get('force_rebuild', False) if request else False
        
        # 0. ê¸°ì¡´ Cloud Run ì„œë¹„ìŠ¤ í™•ì¸
        check_logs = []
        try:
            result = subprocess.run(
                ['gcloud', 'run', 'services', 'list', '--region=asia-northeast3', 
                 '--filter=metadata.name=mk-news-admin', '--format=json'],
                capture_output=True, text=True, timeout=30
            )
            if result.returncode == 0:
                import json
                services = json.loads(result.stdout)
                if services:
                    check_logs.append(f"âš ï¸ ê¸°ì¡´ Cloud Run ì„œë¹„ìŠ¤ ë°œê²¬: {services[0]['metadata']['name']}")
                    check_logs.append(f"   URL: {services[0]['status'].get('url', 'N/A')}")
        except Exception as e:
            check_logs.append(f"ê¸°ì¡´ ì„œë¹„ìŠ¤ í™•ì¸ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        
        # 1. Docker ì´ë¯¸ì§€ í™•ì¸ ë° ë¹Œë“œ
        builder = get_docker_builder()
        image_exists = builder.check_image_exists()
        
        build_logs = []
        if not image_exists or force_rebuild:
            # Docker ì´ë¯¸ì§€ ë¹Œë“œ
            build_result = builder.build_and_push_admin_image(force_rebuild=force_rebuild)
            build_logs = build_result.get('logs', [])
            
            if not build_result.get('success'):
                return {
                    "success": False,
                    "error": "Docker ì´ë¯¸ì§€ ë¹Œë“œ ì‹¤íŒ¨",
                    "logs": check_logs + build_logs
                }
        else:
            build_logs = ["âœ… Artifact Registryì— ì´ë¯¸ì§€ ì¡´ì¬ - ë¹Œë“œ ê±´ë„ˆëœ€"]
        
        # 2. Artifact Registry ì´ë¯¸ì§€ ì¡´ì¬ í™•ì¸ (í•„ìˆ˜)
        if not image_exists and not force_rebuild:
            return {
                "success": False,
                "error": "Artifact Registryì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ê°•ì œ ì¬ë°°í¬ë¥¼ ì²´í¬í•˜ê±°ë‚˜ ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ë¹Œë“œí•˜ì„¸ìš”.",
                "logs": check_logs + build_logs
            }
        
        # 3. Terraform Apply
        result = subprocess.run(['terraform', 'apply', '-auto-approve'], 
                              cwd='terraform', capture_output=True, text=True, timeout=1800)
        
        terraform_logs = result.stdout.split('\n') + result.stderr.split('\n')
        
        all_logs = check_logs + build_logs + ["\n=== Terraform Apply ==="] + terraform_logs
        
        # 4. ë°°í¬ ì„±ê³µ ì‹œ URL ì¶œë ¥
        if result.returncode == 0:
            try:
                output_result = subprocess.run(
                    ['terraform', 'output', '-raw', 'admin_service_url'],
                    cwd='terraform', capture_output=True, text=True, timeout=30
                )
                if output_result.returncode == 0 and output_result.stdout.strip():
                    all_logs.append(f"\nâœ… ë°°í¬ ì™„ë£Œ!")
                    all_logs.append(f"ğŸ“Š ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ URL: {output_result.stdout.strip()}")
            except Exception as e:
                all_logs.append(f"URL ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return {
            "success": result.returncode == 0,
            "logs": all_logs,
            "status": "completed" if result.returncode == 0 else "error"
        }
    except Exception as e:
        return {"success": False, "error": str(e), "logs": []}

@app.get("/api/terraform/outputs")
async def get_terraform_outputs():
    """Terraform ì¶œë ¥ê°’ ì¡°íšŒ"""
    try:
        result = subprocess.run(['terraform', 'output', '-json'], cwd='terraform',
                              capture_output=True, text=True, timeout=30)
        if result.returncode == 0:
            return json.loads(result.stdout)
        return {}
    except Exception as e:
        return {"error": str(e)}

@app.get("/api/terraform/logs")
async def get_terraform_logs():
    """Terraform ë¡œê·¸ ì¡°íšŒ"""
    return {"status": "no logs", "logs": []}

# ========================================
# FTP ì—°ë™ API ì—”ë“œí¬ì¸íŠ¸
# ========================================

@app.post("/api/ftp/connect")
async def ftp_connect(request: dict = None):
    """FTP ì„œë²„ì— ì—°ê²°"""
    global ftp_client_instance
    try:
        environment = request.get('environment', 'test') if request else 'test'
        download_dir = request.get('download_dir', 'ftp_downloads') if request else 'ftp_downloads'
        
        ftp_client_instance = get_ftp_client(environment=environment, download_dir=download_dir)
        
        if ftp_client_instance.connect():
            return {
                "success": True,
                "info": ftp_client_instance.get_connection_info()
            }
        else:
            return {
                "success": False,
                "error": "FTP ì„œë²„ ì—°ê²° ì‹¤íŒ¨"
            }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/ftp/disconnect")
async def ftp_disconnect():
    """FTP ì„œë²„ ì—°ê²° ì¢…ë£Œ"""
    global ftp_client_instance
    try:
        if ftp_client_instance:
            ftp_client_instance.disconnect()
            ftp_client_instance = None
        return {"success": True, "message": "FTP ì—°ê²° ì¢…ë£Œë¨"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/ftp/files")
async def ftp_list_files():
    """FTP ì„œë²„ì˜ íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        if not ftp_client_instance:
            raise HTTPException(status_code=400, detail="FTP ì„œë²„ì— ì—°ê²°ë˜ì§€ ì•ŠìŒ")
        
        files = ftp_client_instance.list_files()
        return {"files": files, "count": len(files)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/ftp/download")
async def ftp_download(request: dict):
    """FTP ì„œë²„ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        if not ftp_client_instance:
            raise HTTPException(status_code=400, detail="FTP ì„œë²„ì— ì—°ê²°ë˜ì§€ ì•ŠìŒ")
        
        remote_path = request.get('remote_path')
        local_filename = request.get('local_filename')
        delete_after_download = request.get('delete_after_download', False)
        
        if not remote_path:
            raise HTTPException(status_code=400, detail="remote_path í•„ìˆ˜")
        
        result = ftp_client_instance.download_file(
            remote_path,
            local_filename,
            delete_after_download
        )
        
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/ftp/download-all")
async def ftp_download_all(request: dict = None):
    """FTP ì„œë²„ì˜ ëª¨ë“  íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        if not ftp_client_instance:
            raise HTTPException(status_code=400, detail="FTP ì„œë²„ì— ì—°ê²°ë˜ì§€ ì•ŠìŒ")
        
        remote_path = request.get('remote_path', '.') if request else '.'
        delete_after_download = request.get('delete_after_download', False) if request else False
        
        results = ftp_client_instance.download_all_files(remote_path, delete_after_download)
        
        return {
            "success": True,
            "results": results,
            "total": len(results),
            "succeeded": len([r for r in results if r['success']]),
            "failed": len([r for r in results if not r['success']])
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/ftp/connection-info")
async def ftp_get_connection_info():
    """FTP ì—°ê²° ì •ë³´ ì¡°íšŒ"""
    try:
        if not ftp_client_instance:
            return {"connected": False, "error": "FTP ì„œë²„ì— ì—°ê²°ë˜ì§€ ì•ŠìŒ"}
        
        return {
            "connected": True,
            "info": ftp_client_instance.get_connection_info()
        }
    except Exception as e:
        return {"connected": False, "error": str(e)}

# FTP íŒŒì´í”„ë¼ì¸ API
@app.post("/api/ftp/pipeline")
async def ftp_pipeline_execute(request: dict = None, background_tasks: BackgroundTasks = None):
    """FTP ë‹¤ìš´ë¡œë“œ â†’ GCS ì €ì¥ â†’ ë²¡í„° ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    try:
        request_data = request or {}
        environment = request_data.get('environment', 'test')
        delete_after_download = request_data.get('delete_after_download', False)
        upload_to_gcs = request_data.get('upload_to_gcs', True)
        process_embeddings = request_data.get('process_embeddings', True)
        upload_to_vector_search = request_data.get('upload_to_vector_search', True)
        
        # ì²˜ë¦¬ ë¡œê·¸ ìƒì„±
        db = next(get_db())
        log_entry = ProcessingLog(
            process_type="embedding",
            status="processing",
            message="FTP íŒŒì´í”„ë¼ì¸ ì‹œì‘"
        )
        db.add(log_entry)
        db.commit()
        job_id = str(log_entry.id)
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ì‹¤í–‰
        background_tasks.add_task(
            execute_ftp_pipeline_background,
            environment,
            delete_after_download,
            upload_to_gcs,
            process_embeddings,
            upload_to_vector_search,
            job_id
        )
        
        return {
            "success": True,
            "message": "FTP íŒŒì´í”„ë¼ì¸ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "job_id": job_id
        }
            
    except Exception as e:
        logger.error(f"FTP íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "message": f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
        }


def execute_ftp_pipeline_background(
    environment: str,
    delete_after_download: bool,
    upload_to_gcs: bool,
    process_embeddings: bool,
    upload_to_vector_search: bool,
    job_id: str
):
    """FTP íŒŒì´í”„ë¼ì¸ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰"""
    db = next(get_db())
    try:
        # FTP íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        pipeline = FTPPipeline(environment=environment)
        
        # FTP ì—°ê²°
        if not pipeline.connect_ftp():
            raise Exception("FTP ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
        
        try:
            # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            result = pipeline.process_ftp_downloads(
                delete_after_download=delete_after_download,
                upload_to_gcs=upload_to_gcs,
                create_embeddings=process_embeddings
            )
            
            # ì²˜ë¦¬ ì™„ë£Œ ë¡œê·¸ ì—…ë°ì´íŠ¸
            log_entry = db.query(ProcessingLog).filter(
                ProcessingLog.id == int(job_id)
            ).first()
            if log_entry:
                log_entry.status = "success"
                log_entry.message = f"íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: ë‹¤ìš´ë¡œë“œ {result.get('stats', {}).get('downloaded', 0)}ê°œ, ì„ë² ë”© {result.get('stats', {}).get('embedded', 0)}ê°œ"
                db.commit()
            
        finally:
            pipeline.disconnect_ftp()
            
    except Exception as e:
        logger.error(f"FTP íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë¡œê·¸ ì—…ë°ì´íŠ¸
        log_entry = db.query(ProcessingLog).filter(
            ProcessingLog.id == int(job_id)
        ).first()
        if log_entry:
            log_entry.status = "error"
            log_entry.message = f"íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {str(e)}"
            db.commit()
    finally:
        db.close()

@app.get("/api/gcs/files")
async def gcs_list_files(request: dict = None):
    """GCS ë²„í‚·ì˜ íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        gcs_client = GCSClient()
        prefix = request.get('prefix', '') if request else ''
        files = gcs_client.list_files(prefix=prefix)
        return {"files": files, "count": len(files)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/xml/files")
async def xml_list_files():
    """XML íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        # FTP ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬ì—ì„œ XML íŒŒì¼ ëª©ë¡ ì¡°íšŒ
        download_dir = Path("ftp_downloads")
        if not download_dir.exists():
            return {"success": True, "files": []}
        
        xml_files = []
        for file_path in download_dir.glob("*.xml"):
            stat = file_path.stat()
            xml_files.append({
                "name": file_path.name,
                "size": stat.st_size,
                "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "path": str(file_path)
            })
        
        return {"success": True, "files": xml_files}
    except Exception as e:
        logger.error(f"XML íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return {"success": False, "error": str(e)}

@app.delete("/api/gcs/files/{file_path:path}")
async def gcs_delete_file(file_path: str):
    """GCSì—ì„œ íŒŒì¼ ì‚­ì œ"""
    try:
        gcs_client = GCSClient()
        result = gcs_client.delete_file(file_path)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/embedding-jobs")
async def get_embedding_jobs(limit: int = 50):
    """ì„ë² ë”© ì‘ì—… ëª©ë¡ ì¡°íšŒ"""
    try:
        db = next(get_db())
        jobs = db.query(ProcessingLog).filter(
            ProcessingLog.process_type.in_(['embedding', 'vector_upload'])
        ).order_by(ProcessingLog.timestamp.desc()).limit(limit).all()
        
        return {
            "success": True,
            "jobs": [
                {
                    "id": str(job.id),
                    "filename": job.message.split(":")[0] if ":" in job.message else job.message,
                    "status": job.status,
                    "progress": 100 if job.status == "success" else 50 if job.status == "processing" else 0,
                    "articles_count": 0,
                    "embeddings_count": 0,
                    "processing_time": (job.processing_time if hasattr(job, 'processing_time') else 0) / 1000,
                    "created_at": job.timestamp.isoformat(),
                    "error": job.error if hasattr(job, 'error') and job.error else None,
                }
                for job in jobs
            ]
        }
    except Exception as e:
        logger.error(f"ì„ë² ë”© ì‘ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return {"success": False, "error": str(e), "jobs": []}

@app.get("/api/embedding-stats")
async def get_embedding_stats():
    """ì„ë² ë”© í†µê³„ ì¡°íšŒ"""
    try:
        db = next(get_db())
        total_jobs = db.query(ProcessingLog).filter(
            ProcessingLog.process_type.in_(['embedding', 'vector_upload'])
        ).count()
        completed_jobs = db.query(ProcessingLog).filter(
            ProcessingLog.process_type.in_(['embedding', 'vector_upload']),
            ProcessingLog.status == "success"
        ).count()
        failed_jobs = db.query(ProcessingLog).filter(
            ProcessingLog.process_type.in_(['embedding', 'vector_upload']),
            ProcessingLog.status == "error"
        ).count()
        
        # ë²¡í„° ì¸ë±ìŠ¤ì—ì„œ ì„ë² ë”© ìˆ˜ ê°€ì ¸ì˜¤ê¸°
        vector_count = 0
        try:
            index_response = await get_vector_index_status()
            if index_response and index_response.get("indexes"):
                for idx in index_response["indexes"]:
                    vector_count += idx.get("total_vectors", 0)
        except:
            pass
        
        return {
            "success": True,
            "total_jobs": total_jobs,
            "completed_jobs": completed_jobs,
            "failed_jobs": failed_jobs,
            "total_embeddings": vector_count,
            "avg_processing_time": 5.2,  # ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”
        }
    except Exception as e:
        logger.error(f"ì„ë² ë”© í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return {"success": False, "error": str(e)}

@app.get("/api/embedding-jobs/{job_id}")
async def get_embedding_job(job_id: str):
    """ì„ë² ë”© ì‘ì—… ìƒì„¸ ì¡°íšŒ"""
    try:
        db = next(get_db())
        job = db.query(ProcessingLog).filter(
            ProcessingLog.id == int(job_id)
        ).first()
        
        if not job:
            return {"success": False, "error": "ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        return {
            "success": True,
            "job": {
                "id": str(job.id),
                "filename": job.message.split(":")[0] if ":" in job.message else job.message,
                "status": job.status,
                "progress": 100 if job.status == "success" else 50 if job.status == "processing" else 0,
                "message": job.message,
                "created_at": job.timestamp.isoformat(),
                "processing_time": (job.processing_time if hasattr(job, 'processing_time') else 0) / 1000,
            }
        }
    except Exception as e:
        logger.error(f"ì„ë² ë”© ì‘ì—… ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return {"success": False, "error": str(e)}

@app.post("/api/embedding-jobs/{job_id}/stop")
async def stop_embedding_job(job_id: str):
    """ì„ë² ë”© ì‘ì—… ì¤‘ì§€"""
    try:
        db = next(get_db())
        job = db.query(ProcessingLog).filter(
            ProcessingLog.id == int(job_id)
        ).first()
        
        if not job:
            return {"success": False, "error": "ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        if job.status == "processing":
            job.status = "error"
            job.message = f"{job.message} (ì¤‘ì§€ë¨)"
            db.commit()
            return {"success": True, "message": "ì‘ì—…ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."}
        else:
            return {"success": False, "error": "ì²˜ë¦¬ ì¤‘ì¸ ì‘ì—…ë§Œ ì¤‘ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        logger.error(f"ì„ë² ë”© ì‘ì—… ì¤‘ì§€ ì‹¤íŒ¨: {str(e)}")
        return {"success": False, "error": str(e)}

@app.post("/api/upload-xml")
async def upload_xml_file(
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks = None
):
    """XML íŒŒì¼ ì—…ë¡œë“œ ë° ì„ë² ë”© ì²˜ë¦¬"""
    try:
        # ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
        upload_dir = Path("uploaded_xml")
        upload_dir.mkdir(exist_ok=True)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_path = upload_dir / f"{timestamp}_{file.filename}"
        
        # íŒŒì¼ ì €ì¥
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        logger.info(f"XML íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file_path}")
        
        # ì²˜ë¦¬ ë¡œê·¸ ìƒì„±
        db = next(get_db())
        log_entry = ProcessingLog(
            process_type="embedding",
            status="processing",
            message=f"{file.filename}: ì—…ë¡œë“œ ì™„ë£Œ"
        )
        db.add(log_entry)
        db.commit()
        job_id = str(log_entry.id)
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ì„ë² ë”© ì²˜ë¦¬
        background_tasks.add_task(
            process_xml_embeddings,
            str(file_path),
            job_id
        )
        
        return {
            "success": True,
            "message": "íŒŒì¼ ì—…ë¡œë“œê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "job_id": job_id,
            "filename": file.filename
        }
    except Exception as e:
        logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return {"success": False, "error": str(e)}


def process_xml_embeddings(file_path: str, job_id: str):
    """XML íŒŒì¼ ì„ë² ë”© ì²˜ë¦¬ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…"""
    db = next(get_db())
    try:
        logger.info(f"XML ì„ë² ë”© ì²˜ë¦¬ ì‹œì‘: {file_path}")
        
        # XML íŒŒì¼ íŒŒì‹±
        articles = xml_processor.process_file(file_path)
        logger.info(f"íŒŒì‹±ëœ ê¸°ì‚¬ ìˆ˜: {len(articles)}")
        
        # ì„ë² ë”© ìƒì„± ë° Vector Search ì—…ë¡œë“œ
        processed_count = 0
        embedding_count = 0
        
        for article in articles:
            try:
                # ê¸°ì‚¬ ì €ì¥
                db_article = Article(
                    title=article.get('title', ''),
                    content=article.get('content', ''),
                    metadata=json.dumps(article.get('metadata', {}))
                )
                db.add(db_article)
                db.commit()
                
                # ì„ë² ë”© ìƒì„±
                if embedding_service:
                    embedding_vector = embedding_service.generate_embedding(
                        article.get('content', '')
                    )
                    
                    # Vector Searchì— ì—…ë¡œë“œ
                    if vector_indexer:
                        vector_indexer.upload_vector(
                            vector=embedding_vector,
                            article_id=str(db_article.id),
                            metadata={
                                'title': article.get('title', ''),
                                'content': article.get('content', '')[:500]
                            }
                        )
                        embedding_count += 1
                
                processed_count += 1
            except Exception as e:
                logger.error(f"ê¸°ì‚¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                continue
        
        # ì²˜ë¦¬ ì™„ë£Œ ë¡œê·¸ ì—…ë°ì´íŠ¸
        log_entry = db.query(ProcessingLog).filter(
            ProcessingLog.id == int(job_id)
        ).first()
        if log_entry:
            log_entry.status = "success"
            log_entry.message = f"ì²˜ë¦¬ ì™„ë£Œ: {processed_count}ê°œ ê¸°ì‚¬, {embedding_count}ê°œ ì„ë² ë”©"
            db.commit()
        
        logger.info(f"XML ì„ë² ë”© ì²˜ë¦¬ ì™„ë£Œ: {file_path}")
        
    except Exception as e:
        logger.error(f"XML ì„ë² ë”© ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        # ì˜¤ë¥˜ ë¡œê·¸ ì—…ë°ì´íŠ¸
        log_entry = db.query(ProcessingLog).filter(
            ProcessingLog.id == int(job_id)
        ).first()
        if log_entry:
            log_entry.status = "error"
            log_entry.message = f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            db.commit()
    finally:
        db.close()

# ========================================
# GCP ì¸ì¦ API
# ========================================

@app.get("/api/gcp/auth-status")
async def get_gcp_auth_status():
    """GCP ì¸ì¦ ìƒíƒœ ì¡°íšŒ"""
    try:
        # gcloud auth listë¡œ ì¸ì¦ëœ ê³„ì • í™•ì¸
        result = subprocess.run(
            ['gcloud', 'auth', 'list', '--filter=status:ACTIVE', '--format=json'],
            capture_output=True,
            text=True,
            timeout=10
        )
        
        if result.returncode == 0 and result.stdout.strip():
            accounts = json.loads(result.stdout)
            if accounts and len(accounts) > 0:
                # í™œì„± ê³„ì •ì´ ìˆìœ¼ë©´ í”„ë¡œì íŠ¸ ID ê°€ì ¸ì˜¤ê¸°
                project_result = subprocess.run(
                    ['gcloud', 'config', 'get-value', 'project'],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                project_id = project_result.stdout.strip() if project_result.returncode == 0 else None
                
                return {
                    "authenticated": True,
                    "accounts": accounts,
                    "active_account": accounts[0].get('account', ''),
                    "project_id": project_id
                }
        
        return {
            "authenticated": False,
            "accounts": [],
            "active_account": None,
            "project_id": None
        }
    except Exception as e:
        logger.error(f"GCP ì¸ì¦ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        return {
            "authenticated": False,
            "error": str(e),
            "accounts": [],
            "active_account": None,
            "project_id": None
        }

@app.post("/api/gcp/init-login")
async def init_gcp_login():
    """GCP ë¡œê·¸ì¸ ì‹œì‘ (ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ ë¡œê·¸ì¸)"""
    try:
        # ë¸Œë¼ìš°ì € ìë™ ì‹¤í–‰ ì‹œë„ (ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•)
        try:
            result = subprocess.run(
                ['gcloud', 'auth', 'login', '--brief', '--no-launch-browser'],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            output = result.stdout + result.stderr
            
            # URLê³¼ ì¸ì¦ ì½”ë“œ ì¶”ì¶œ
            import re
            url_pattern = r'https://accounts\.google\.com[^\s]+'
            code_pattern = r'(\d{4}-\d{4}-\d{4}-\d{4})'
            
            urls = re.findall(url_pattern, output)
            codes = re.findall(code_pattern, output)
            
            auth_url = urls[0] if urls else None
            verification_code = codes[0] if codes else None
            
            if auth_url:
                return {
                    "success": True,
                    "auth_url": auth_url,
                    "verification_code": verification_code,
                    "message": "ë¸Œë¼ìš°ì €ì—ì„œ Google ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•˜ì„¸ìš”.",
                    "instructions": f"ì•„ë˜ URLì„ í´ë¦­í•˜ì—¬ ë¸Œë¼ìš°ì €ì—ì„œ ë¡œê·¸ì¸í•˜ì„¸ìš”. ì¸ì¦ ì½”ë“œê°€ í•„ìš”í•˜ë©´ '{verification_code}'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
                }
            else:
                # URLì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ë¸Œë¼ìš°ì € ìë™ ì‹¤í–‰
                subprocess.Popen(['gcloud', 'auth', 'login', '--brief'], 
                               stdout=subprocess.DEVNULL, 
                               stderr=subprocess.DEVNULL)
                return {
                    "success": True,
                    "auth_url": None,
                    "verification_code": None,
                    "message": "ë¸Œë¼ìš°ì €ê°€ ìë™ìœ¼ë¡œ ì—´ë ¸ìŠµë‹ˆë‹¤. Google ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•˜ì„¸ìš”.",
                    "instructions": "ë¸Œë¼ìš°ì €ì—ì„œ Google ê³„ì •ì„ ì„ íƒí•˜ê³  ê¶Œí•œì„ ìŠ¹ì¸í•˜ì„¸ìš”."
                }
        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "error": "íƒ€ì„ì•„ì›ƒ",
                "message": "ì¸ì¦ í”„ë¡œì„¸ìŠ¤ê°€ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë ¸ìŠµë‹ˆë‹¤."
            }
    except Exception as e:
        logger.error(f"GCP ë¡œê·¸ì¸ ì‹œì‘ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "error": str(e),
            "message": "GCP ë¡œê·¸ì¸ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ ì§ì ‘ 'gcloud auth login' ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”."
        }

@app.post("/api/gcp/complete-login")
async def complete_gcp_login():
    """GCP ë¡œê·¸ì¸ ì™„ë£Œ í™•ì¸"""
    try:
        # ì¸ì¦ ìƒíƒœ ë‹¤ì‹œ í™•ì¸
        result = subprocess.run(
            ['gcloud', 'auth', 'list', '--filter=status:ACTIVE', '--format=json'],
            capture_output=True,
            text=True,
            timeout=10
        )
        
        if result.returncode == 0 and result.stdout.strip():
            accounts = json.loads(result.stdout)
            if accounts and len(accounts) > 0:
                project_result = subprocess.run(
                    ['gcloud', 'config', 'get-value', 'project'],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                project_id = project_result.stdout.strip() if project_result.returncode == 0 else None
                
                return {
                    "success": True,
                    "authenticated": True,
                    "active_account": accounts[0].get('account', ''),
                    "project_id": project_id
                }
        
        return {
            "success": False,
            "authenticated": False,
            "message": "ì•„ì§ ì¸ì¦ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì €ì—ì„œ ë¡œê·¸ì¸ì„ ì™„ë£Œí•˜ì„¸ìš”."
        }
    except Exception as e:
        logger.error(f"GCP ë¡œê·¸ì¸ ì™„ë£Œ í™•ì¸ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "authenticated": False,
            "error": str(e)
        }

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    try:
        init_database()
        logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
